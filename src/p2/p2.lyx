#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass amsart
\use_default_options true
\master ../main.lyx
\begin_removed_modules
theorems-ams
\end_removed_modules
\begin_modules
eqs-within-sections
figs-within-sections
tabs-within-sections
theorems-ams-chap-bytype
theorems-ams-extended-chap-bytype
algorithm2e
customHeadersFooters
enumitem
logicalmkup
todonotes
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "Libertinus Serif"
\font_sans "default" "Avenir LT Std"
\font_typewriter "default" "Source Code Pro"
\font_math "auto" "default"
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 93
\use_microtype true
\use_dash_ligatures true
\graphics default
\default_output_format pdf5
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing other 1.09
\use_hyperref true
\pdf_title "Sample Thesis"
\pdf_author "Shengdi »shc« Chen"
\pdf_subject "Sample Thesis by Shengdi »shc« Chen, supervised by himself"
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\pdf_quoted_options "linkcolor=black,  frenchlinks=true, citecolor=black, urlcolor=blue, filecolor=blue, pdfpagelayout=OneColumn, pdfnewwindow=true, pdfstartview=XYZ, plainpages=false"
\papersize a4paper
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine biblatex
\cite_engine_type numerical
\biblatex_bibstyle nature
\biblatex_citestyle alphabetic-verb
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 0.75in
\topmargin 0.75in
\rightmargin 0.75in
\bottommargin 1in
\headsep 0.3in
\footskip 0.3in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side right
\quotes_style danish
\dynamic_quotes 1
\papercolumns 1
\papersides 2
\paperpagestyle fancy
\listings_params "basicstyle={\ttfamily\normalsize},commentstyle={\sffamily},columns=fullflexible,numbers=left,numberstyle={\ttfamily\scriptsize},stepnumber=1,numberblanklines=false,firstline=1,numbersep=9pt,frame=tlb,framexleftmargin=3pt,framextopmargin=2pt,framexbottommargin=1pt,aboveskip={\medskipamount},belowskip={\medskipamount},captionpos=b,floatplacement=tbp,tabsize=4,resetmargins=false,breaklines=true,breakatwhitespace=false,breakautoindent=true,breakindent=0pt,prebreak={...},postbreak={...},extendedchars=true"
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Essentials from Primal Wasserstein IL
\end_layout

\begin_layout Subsection
The RL problem
\end_layout

\begin_layout Standard
The Markov-Decision-Process (MDP) framework as introduced in [REF] characterizes
 agent-environment interaction over time-horizon 
\begin_inset Formula $t\in T$
\end_inset

 with action 
\begin_inset Formula $a_{t}$
\end_inset

 drawn from the time-invariant action-space 
\begin_inset Formula $A$
\end_inset

 leading to state transition:
\begin_inset Formula 
\[
S\in s_{t}\stackrel[\text{env}]{a_{t}}{\longrightarrow}s_{t+1}\in S
\]

\end_inset

of the environment, yielding a reward 
\begin_inset Formula $r_{t}$
\end_inset

.
\end_layout

\begin_layout Standard
The decision for the action 
\begin_inset Formula $a_{t}$
\end_inset

 of an agent is provided by policy 
\begin_inset Formula $\pi$
\end_inset

 of policy-space 
\begin_inset Formula $\Pi$
\end_inset

:
\begin_inset Formula 
\[
s_{\star}\stackrel{\pi}{\longrightarrow}a_{t}
\]

\end_inset

Central to Reinforcement-Learning (RL) is the search of the optimal policy
 
\begin_inset Formula $\pi^{\star}$
\end_inset

 that maximizes the expected 
\begin_inset Formula $\gamma$
\end_inset

-discounted summation of all rewards 
\begin_inset Formula $r$
\end_inset

, otherwise referred to as the expected 
\begin_inset Quotes xld
\end_inset

return
\begin_inset Quotes xrd
\end_inset

.
\end_layout

\begin_layout Subsection
The Wasserstein Distance
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
As discussed in 
\begin_inset CommandInset citation
LatexCommand cite
key "opt-transport-villani"
literal "false"

\end_inset

, the 
\begin_inset Formula $p^{\text{th}}$
\end_inset

-order Wasserstein
\begin_inset Foot
status open

\begin_layout Plain Layout
named after Leonid Vaseršteĭn (in Russian: Леонид Нисонович Васерштейн)
\end_layout

\end_inset

 distance is defined as follows:
\begin_inset Formula 
\begin{align*}
 & ^{fff}\\
 & \equiv\underset{\theta\in\Theta}{\inf}\left\{ \mathop{\int}\right\} 
\end{align*}

\end_inset


\begin_inset Formula 
\[
\begin{alignedat}{1}\mathcal{W} & \coloneqq\left(\underset{\theta\in\Theta}{\inf}\left\{ \underset{\left(x,y\right)}{\mathbb{E}}\left[d\left(x,y\right)\right]\right\} \right)^{\nicefrac{1}{p}}\\
\\
\end{alignedat}
\]

\end_inset

which, interpreted with the earth's movers analogy (Villani-2008), is equivalent
ly formulated as follows:
\begin_inset Formula 
\[
\pi^{\star}\coloneqq\underset{\theta\in\Theta}{\inf}\left\{ d\left(\right)\theta_{\pi}\right\} 
\]

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "main-paper"
literal "false"

\end_inset

 enumerates various desirable properties of the Wasserstein distance: in
 particular, it is a true distance (in contrast with 
\begin_inset Formula $f$
\end_inset

-divergences used commonly in ?-Learning (IRL or adversary?)) with guaranteed
 smoothness.
 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
The PW-IL algorithm
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Solving for the optimal solution conforming to the above definition requires
 trajectory information of the entire episode (before the environment has
 to be reset for further agent inputs).
 This requirement is bypassed by the Primal Wasserstein IL (PW-IL) algorithm
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "main-paper"
literal "false"

\end_inset

, where the following optimization problem is solved instead:
\begin_inset Formula 
\[
\pi^{\star}\coloneqq\underset{\theta\in\Theta}{\inf}\left\{ d\left(\right)\theta_{\pi}\right\} 
\]

\end_inset

The optimizer is deliberately non-optimal with respect to the original Wasserste
in distance: in fact, the underlying optimization-problem guarantees an
 upper-bound for the Wasserstein distance.
\end_layout

\begin_layout Plain Layout
The non-optimal solution is based on the following 
\begin_inset Quotes xld
\end_inset

greedy-coupling
\begin_inset Quotes xrd
\end_inset


\end_layout

\end_inset


\end_layout

\end_body
\end_document
